---
title: "Simulation output"
author: "Remco Benthem de Grave"
output: 
  html_document:
    fig_width: 9
    fig_height: 6
params:
   datadir: ""
   paramsets: ""
   totalsimtime: ""
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE}

#### PREPARATION ####

#make time stamp for later calculation of rendering time
start.time <- Sys.time()

#LOAD LIBRARIES

#function to load a library and install it when it is not yet installed
package <- function(pack) { #function to load a library and install it when it is not yet installed
  if (!pack %in% installed.packages()) {install.packages(pack) }
  library(pack,character.only=TRUE)}

package("ggplot2")
package("plyr")
package("dplyr")
package("tidyr")
package("tcltk")
package("ggthemes")
package("knitr")

# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- t(matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = ceiling(numPlots/cols), nrow = cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

```{r, include = FALSE, warning = FALSE}

#### SET DATA PATH (ONLY RELEVANT IN THE SCRIPT IS RAN MANUALLY) #### 

if(!exists("datadir")){
  choicedir<-tk_choose.dir(getwd(), "Show folder with data to publish")

  #list the file paths to the different simulations in the folder (using a bit of a complex way to get there)
  subdirlist <- unlist(lapply(list.dirs(choicedir), function(i) 
      unlist(strsplit(i,"/"))[length(unlist(strsplit(i,"/")))])) #for each folder path...
    #...abstract the name of the last folder in the folderpath
    subdirlist <- subdirlist[subdirlist %in% dir(choicedir)] #keep only those that are a direct subpath of...
    #...the choicedir
    subdirlist <- subdirlist[grepl('sim', subdirlist)] #test for each subdir if it contains 'sim' ...
    #...and keep only those
    datadir <- file.path(choicedir,subdirlist)
    if(length(datadir)==0){datadir<-choicedir} #if the choicefolder already contains the simulation data, ...
    #...then keep this folder
    
    ##define paramsets (if the script is not rendered from the simulation script, 'paramsets' is determined
    #from the data)
    
    #get settings for each simulation
    set <- function(ddir){load(file.path(ddir,"settings.Rdata"));return(settings)}
    settingsset <- lapply(datadir, function(ddir) set(ddir))
    
    #test which settings are different between 2 simulations
    uparam<-unique(unlist(lapply(seq_along(settingsset), function(i)
      which(lapply(names(settingsset[[1]]), function(name)
        unique(sort(settingsset[[1]][[name]]==settingsset[[i]][[name]]),decreasing = F)[1])==F)
    )))
    
    #create the merged paramsets
    if(length(uparam)==0){paramsets<-NULL}else{paramsets=lapply(settingsset, function(sett) sett[uparam])}
}
if(!exists("paramsets")){paramsets<-NULL}
```

##### Included simulations
```{r, echo = FALSE, warning = FALSE, results='asis'}

#### PRINT TABLE OF INCLUDED SIMULATION PATHS #### 
shortdatadir <- function(ddir){
  ddira <- unlist(strsplit(ddir, "/"))
  return(paste(ddira[which(ddira=="simoutput"):length(ddira)],collapse = "/"))}
kable(unlist(lapply(datadir, function(ddir) shortdatadir(ddir))))
```

##### Variation between simulations
```{r, echo = FALSE, warning = FALSE, results='asis'}

#### DISPLAY THE PARAMETERS DEFINED IN PARAMSETS (THOSE THAT VARY BETWEEN THE SIMULATIONS) #### 

if(length(datadir)>1){
    repl <- function(paramset){
    #function to reshape the parameter list into something printable by kable
     if("dayoff" %in% names(paramset)){
       paramset$dayoff=unlist(paramset$dayoff)
       paramset$dayoff=(paste(as.character(
             factor(unique(paramset$dayoff%%7), levels=c(0,1,2,3,4,5,6), labels=c('Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday')
             )), collapse = " "))}
    if("waketime" %in% names(paramset)){
      paramset$waketime=
        with(paramset, paste0(floor(waketime),':',sprintf("%02d", round(waketime[1]%%1*60))))}
    if("worktime" %in% names(paramset)){
      paramset$worktime=unlist(paramset$worktime)
      paramset$worktime=
        with(paramset, paste0(floor(worktime[1]),':',sprintf("%02d", round(worktime[1]%%1*60)),' to ',floor(worktime[2]),':',sprintf("%02d", round(worktime[2]%%1*60))))}
    if("savedays" %in% names(paramset)){
      paramset$savedays=paste(settingsfortable$savedays, collapse = " ")}
    if("samplepeople" %in% names(paramset)){
      paramset$samplepeople=paste(settingsfortable$samplepeople, collapse = " ")}
    return(as.data.frame(paramset))
  }

  paramssetsshow=repl(paramsets[[1]])
  for(i in 2:length(paramsets)){paramssetsshow<-rbind(paramssetsshow,repl(paramsets[[i]]))}
  row.names(paramssetsshow)= paste("sim",seq_along(paramsets))
  kable(paramssetsshow)

}
```

##### Other settings (identical between the simulations):
```{r, echo = FALSE, warning=FALSE}

#### DISPLAY THE OTHER PARAMETERS (THOSE THAT ARE IDENTICAL BETWEEN THE SIMULATIONS) #### 

load(file.path(datadir[1],"settings.Rdata"))
settingsfortable <- settings

#first conversion of parameter names in some older versions
settingsfortable$dayoff<-paste(as.character(factor(unique(settingsfortable$dayoff%%7), levels=c(0,1,2,3,4,5,6), labels=c('Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday'))), collapse = " ")

settingsfortable$halflifeM<-paste0(round(settingsfortable$halflifeM,digits = 3))

settingsfortable$halflifeSD<-paste0(round(settingsfortable$halflifeSD,digits = 3))

settingsfortable$waketime<-with(settingsfortable, paste0(floor(waketime),':',sprintf("%02d", round(waketime[1]%%1*60))))

settingsfortable$work.unif<-with(settingsfortable, paste0(work.unif[1],' to ',work.unif[2]))

settingsfortable$worktime<-with(settingsfortable, paste0(floor(worktime[1]),':',sprintf("%02d", round(worktime[1]%%1*60)),' to ',floor(worktime[2]),':',sprintf("%02d", round(worktime[2]%%1*60))))

settingsfortable$kHPA<-paste0(round(settingsfortable$kHPA,digits = 3))

settingsfortable$delay<-paste0(round(settingsfortable$delay,digits = 3))

settingsfortable$savedays<-paste(settingsfortable$savedays, collapse = " ")

settingsfortable$samplepeople<-paste(settingsfortable$samplepeople, collapse = " ")

names(settingsfortable) <-  c(
  "samples.per.hour",
  "days",
  "people",
  "integration.method",
  'nighttime.HPA.axis.impulses.population.mean',
  'shape.population.distribution.nighttime.HPA.axis.impulses',
  "time.of.awakening",
  'distribution.type.used',
  'worktime.HPA.axis.impulses.population.mean',
  'shape.population.distribution.worktime.HPA.axis.impulses',
  'uniform.distribution.range',
  "worktime",
  "day.stress.anticipation",
  "off.days",
  "HPA.scaling.factor",
  "delay.cortisol.response.hour",
  "cortisol.halflife.M.hour", 
  "cortisol.halflife.SD.hour", 
  "threshold.allostatic.load",
  "recovery.factor.dynamic.load",
  "disease.threshold",
  "saved.days",
  "sampled.people")

if(length(datadir)>1){settingsfortable <- settingsfortable[-which(names(settings) %in% names(paramsets[[1]]))]} #remove parameters that are varied between simulations

settingsfortable<-t(as.data.frame(settingsfortable)); colnames(settingsfortable)=c('defaults')

kable(settingsfortable)
```

##### Evaluations:
```{r, echo = FALSE}

#### DISPLAY THE SIMULATION LOG #### 

logsim <- function(ddir){
  load(file.path(ddir,"simlog.Rdata"))
  simlog<-as.data.frame(simlog)
  simlog[,c(1:3)] <- paste(round(as.numeric(simlog[,c(1:3)]), digits = 3),'min')
  return(simlog)}

simlogs<-logsim(datadir[1])
if(length(datadir)>1){for(i in 2:length(datadir)){simlogs<-rbind(simlogs,logsim(datadir[i]))}}
row.names(simlogs)= paste("sim",seq_along(datadir))
kable(simlogs)
```

#### Actual distribution of night- and worktime HPA-axis impulses:
```{r, echo = FALSE, warning = FALSE}
#### DISPLAY DISTRIBUTION OF NIGHT AND WORK IMPULSES IN THE POPULATION ####

densgraph <- function(ddir){
  #function that creates a density plot of the wake and stressor frequencies
  
  #read data that contains impulse frequencies per person
  simpopulation <- read.csv(file.path(ddir,"simpopulation.csv"))[,-c(1,2,3,6,7,8,9)]
  
  if(names(simpopulation) == c("wakefM_pp","stressfM_pp")){names(simpopulation) <- c("night.f.mean_pp","work.f.mean_pp")}
  
  #plot correlation between work impulses and night impulses
  ggplot(simpopulation, aes(x=night.f.mean_pp,y=work.f.mean_pp)) + geom_point() + 
    labs(x="night impulses",y="work impulses") + theme_minimal()
     
  simpopulation <- gather(simpopulation, key = impulsetype, value = freq)
  simpopulation$impulsetype <- factor(simpopulation$impulsetype, levels = c("night.f.mean_pp","work.f.mean_pp"),
                                      labels = c("night impulses","work impulses"))

  #plot impulse distributions
  ggplot(simpopulation, aes(freq,color=impulsetype,fill=impulsetype)) + geom_density(alpha=0.55) + 
        labs(x="Impulse frequency") + theme_minimal()  + theme(legend.position=c(.8, .8))
}

#obtain desity graphs for all simulations if there is any variation in the number of impulses
if(sum(c("night.f.mean","work.f.mean") %in% names(paramsets[[1]]))>0){
  l_ply(datadir, function(i) densgraph(i))
  }else{densgraph(datadir[1])} #otherwise only show the density for one of the simulations
```


##### Cohort data Miller et al. (2017).
![](Millergraph.png)

##### Simulated cortisol profiles since awakening (population averages)

```{r, echo = FALSE, warning = FALSE}

# CREATE GRAPH OF AVERAGE CORTISOL LEVELS SINCE AWAKENING (AS COMPARISON WITH THE DATA FROM MILLER ET AL.) 

makeQgraph <- function(ddir){#first create plot of quantiles since awakening, as in Miller et al.
  
  #read data
  data <- read.csv(file.path(ddir,"Qdata.csv"))[,-c(1,2)]
  load(file.path(ddir,"settings.Rdata"))

  #calculate quantiles in data
  Qdata <- data %>% group_by(time) %>% summarise(
    Q10=quantile(C,probs=.10),
    Q25=quantile(C,probs=.25),
    Q50=quantile(C,probs=.50),
    Q75=quantile(C,probs=.75),
    Q90=quantile(C,probs=.90))

  morningpeak <- max(Qdata$Q50)

  #reshape to long data frame for ggplot
  Qdata <- gather(Qdata, key=quantile, value=cortisol, -time)

  #create profiles since awakening (stored but not plotted yet)
  ggplot(subset(Qdata, time>=settings$waketime), aes(x=time-settings$waketime,y=cortisol,group=quantile)) +
    geom_line(aes(linetype=quantile)) +
    scale_linetype_manual(values=c("dotted","twodash","solid","twodash","dotted"),
                         name="Percentile",
                         breaks=c("Q90", "Q75", "Q50", "Q25", "Q10"),
                         labels=c("90th", "75th", "50th", "25th", "10th")) +
    scale_x_continuous(breaks=seq(0, 20, 2)) +
    labs(title=paste("note: morning peak at ",morningpeak), x="time since awakening", y="simulated cortisol [arbitrary units]") +
    theme_minimal() + theme(legend.justification=c(.9,.9), legend.position=c(.9,.9),
                            panel.grid.minor.x=element_blank(), panel.grid.minor.y=element_blank()) +
    coord_cartesian(xlim=c(0,20) ,ylim=c(0, 19))
}

#run the function
lapply(datadir, function(i) makeQgraph(i))
```

##### Night time cortisol profiles Clow et al. (2009).
![](night_cortisol_clow.png)


##### Average cortisol profiles since midnight

```{r, echo = FALSE, warning = FALSE}
# CREATE GRAPH OF AVERAGE CORTISOL LEVELS FROM 6H BEFORE TO 3H AFTER AWAKENING (AS COMPARISON WITH BORN ET AL.)

nightprofile <- function(ddir){
  
  #read data
  Qdata <- read.csv(file.path(ddir,"Qdata.csv"))[,-c(1,2)]
  load(file.path(ddir,"settings.Rdata"))

  #calculate mean and standard 95%-CI of the group data
  nightdata <- data.frame(
    time = unique(Qdata$time),
    M = sapply(unique(Qdata$time), function(t) mean(Qdata$C[which(Qdata$time==t)])),
    SE = sapply(unique(Qdata$time), function(t) sd(Qdata$C[which(Qdata$time==t)])/sqrt(settings$people)))

  ggplot(subset(nightdata, time<=settings$waketime+3 & time>=settings$waketime-6),  aes(x=time,y=M,ymin=M-2*SE,ymax=M+2*SE)) + 
    geom_line() + 
    geom_ribbon(alpha=0.2) +
    geom_vline(xintercept = 7, linetype=2, color="grey") +
    coord_cartesian(xlim=c(settings$waketime-6,settings$waketime+4) ,ylim=c(0,12.5)) +
    scale_x_continuous(breaks=seq(1, 11, 2)) +
    scale_y_continuous(breaks=seq(0, 12, 2)) +
    labs(x="time", y="Simulated cortisol [arbitrary units]") +
    theme_minimal() + theme(legend.position="none", panel.grid.minor.x=element_blank(), panel.grid.minor.y=element_blank())}

#run the function
lapply(datadir, function(i) nightprofile(i))
```

##### 24h cortisol profiles of 17 individuals from Hosseinichimeh et al. (2015).
![](individuals-hosseinichimeh.png)

```{r, echo = FALSE, warning = FALSE}

# CREATE GRAPH OF INDIVIDUAL CORTISOL TIME COURSES OF A RANDOM SAMPLE OF INDIVIDUALS (AS COMPARISON WITH HOSSEINICHIMEH ET AL.)

indivplots <- function(ddir){

  #read data
  Qdata <- read.csv(file.path(ddir,"Qdata.csv"))[,-c(1,2)]
  load(file.path(ddir,"settings.Rdata"))

  #determine the number of individuals in Qdata by looking for 0 in the time array and assign to Qdata
  Qdata$person = rep(seq_along(which(Qdata$time==0)),each=length(Qdata$time)/length(which(Qdata$time==0)))
  Qdata$person = paste("person",Qdata$person)
  Qdata$person <- factor(Qdata$person)
  
  #randomly pick some people to plot
  set.seed(1)
  Qdata=Qdata[which(Qdata$person %in% sample(unique(Qdata$person),10)),]
  
  # ggplot(subset(Qdata, time <= 24), aes(x=time, y=C, group = person)) +
  #   geom_line() + facet_wrap(~ person, ncol = 2) +
  #   labs(x="time [hours]", y=expression("Simulated cortisol [arbitrary units]")) +
  #   theme_minimal() + theme(panel.grid.minor.x=element_blank(), panel.grid.minor.y=element_blank())
  #   scale_x_continuous(breaks=seq(0, 24, 4)) 
  
  #plot individual cortisol profiles of only the first day for comparison with Hosseinichimeh 2015
  individual <- function(data){
    #function to make individual plots for each individual
    ggplot(subset(data, time <= 24), aes(x=time, y=C)) + geom_line() + 
    scale_x_continuous(breaks=seq(0, 24, 4)) +
    ylab("Simulated cortisol") + xlab("time [hours]") +
    theme_minimal() + theme(panel.grid.minor.x=element_blank(), panel.grid.minor.y=element_blank())}
  
  graphs <- lapply(unique(Qdata$person), function(person) individual(Qdata[which(Qdata$person == person),]))

  multiplot(plotlist = graphs, cols = 2)
}

#l_ply(datadir, function(i) indivplots(i))
indivplots(datadir[14])
```

#### Sample of seven days showing variation on all model variables from 5 random simulated people

```{r, echo = FALSE, warning = FALSE}

# CREATE EXAMPLE GRAPH, SHOWING VARIATION ON ALL PARAMETERS FOR 7 SIMULATION DAYS FOR 5 RANDOM PEOPLE 

sampleplots <- function(ddir){
  
  #read data
  load(file.path(ddir,"settings.Rdata"))
  plotsample <- read.csv(file.path(ddir,"plotsample.csv"))[,-c(1,2)]
  
  #include disease state
  plotsample$D <- plotsample$A > settings$eps.D

  #reshape into long format
  plotsample=gather(plotsample, key = "type", value = "value", -c(time,simperson))
  
  #make sure that the order is kept and asign labels
  plotsample$type <- factor(plotsample$type, levels=c("HPA", "C", "L","A","D"), labels=c("Impulses", "Cortisol", "Allostatic strain","Allostatic load","Diseased"), ordered=TRUE)
  
  #write.csv(plotsample, "data_figure8_example_variable_variation.csv", col.names = F)
  
  #plot
  ggplot(plotsample, aes(x=time, y=value)) +
    geom_line() + facet_grid(type ~ simperson, scales="free") +
    ylab("Value [arbitrary units]") + xlab("time [hours]") + theme_minimal() 
} 

#plot samples per simulation
lapply(datadir, function(ddir) sampleplots(ddir))
# ddir = (datadir[14])
# sampleplots(ddir)
# ggsave("sampleplots.pdf")
```


#### odds-ratio of developing disease for varying stressor frequencies 
```{r, echo = FALSE, message = FALSE, warning = FALSE}

# CREATE GRAPH TO INDICATE HOW THE RISK OF DISEASE CHANGES WITH THE FREQUENCY OF WORK STRESSORS

if(sum(c('rho.E','eps.A','eps.D') %in% names(paramsets[[1]]))!=3){

  makeoddsplot <- function(ddir){
    
    #read data
    daydata <- read.csv(file.path(ddir,"daydata.csv"))[,-c(1,2)]
  
    getodds <- function(data){
      if(length(unique(data$Sick))<2 | length(unique(data$work.f.mean))<2) #if all instances are either TRUE of FALSE
      {OR<-upper<-lower<-1
      } else {
        model <- with(data, glm(Sick~scale(work.f.mean), family = binomial()))    #Store odds ratios
        if(model$converged==T){
          OR <- exp(model$coefficients)[2] #position [1] is the intercept...
          lower <- exp(confint(model))[2,1]
          upper <- exp(confint(model))[2,2]} else {
            OR<-upper<-lower<-1
          }
      }
      return(data.frame(day=unique(data$day),OR,lower,upper))
    }
    
    odds <- ldply(unique(daydata$days), function(day) getodds(subset(daydata, days==day)))
    
    print(kable(odds))
    
    #plot odds ratio's
    ggplot(odds, aes(y= OR, x = day)) +
      geom_point() +
      geom_errorbar(aes(ymin=lower, ymax=upper), width=.2) +
      geom_hline(yintercept = 1, linetype=2) +
      scale_x_continuous(breaks=odds$day) +
      #coord_flip() + 
      coord_trans(y="log2") +
      labs(x = "Day", y = "relative disease risk") +
      theme_minimal()
  
    
    # #assess assumptions
    # dwt(odds_model) #Independence of errors (Durbin-Watson)
    # densityplot(rstandard(odds_model)) #check for outliers
    # hist(dfbeta(odds_model)) #influential cases
    # densityplot(hatvalues(odds_model)) #influential cases
    # plot(odds_model)
    #
    # #look at model
    # summary(odds_model)
    #
    # #model fit by Chi2
    # Chi_sq <- odds_model$null.deviance-odds_model$deviance
    # chidf <- odds_model$df.null - odds_model$df.residual
    # chisq.prob <- 1 - pchisq(Chi_sq, chidf)
    # Chi_sq; chidf; chisq.prob
    #
    # #model fit by R2
    # R2.hl<-Chi_sq/odds_model$null.deviance
    # R.cs<-1-exp((odds_model$deviance-odds_model$null.deviance)/nrow(odds.data))
    # R.n<-R.cs/(1-(exp(-(odds_model$null.deviance/nrow(odds.data)))))
    # R2.hl; R.cs; R.n
    
  }
}
  
lapply(datadir, function(i) makeoddsplot(i))
```


```{r, echo = FALSE, message = FALSE, warning = FALSE}

# IF ELASTICITY CONSTANT, ALLOSTATIC LOAD THRESHOLD AND DISEASE THRESHOLD WERE VARIED BETWEEN SIMULATIONS - CREATE GRID GRAPH SHOWING RISK OF DISEASE FOR DIFFERENT FREQUENCIES OF WORK STRESSORS UNDER THE VARYING ARBITRARY PARAMETER CHOISES OF THE ELASTICITY CONSTANT, ALLOSTATIC LOAD THRESHOLD AND DISEASE THRESHOLD 

if(length(datadir)>1 & sum(c('rho.E','eps.A','eps.D') %in% names(paramsets[[1]]))==3){
  
  #function to get the odds per day in the simulation
  getodds <- function(data){
    if(length(unique(data$Sick))<2 | length(unique(data$work.f.mean))<2) #if all instances are either TRUE of FALSE
    {OR<-upper<-lower<-1
    } else {
      model <- with(data, glm(Sick~scale(work.f.mean), family = binomial()))    #Store odds ratios
      if(model$converged==T){
        OR <- exp(model$coefficients)[2] #position [1] is the intercept...
        lower <- exp(confint(model))[2,1]
        upper <- exp(confint(model))[2,2]} else {
          OR<-upper<-lower<-1
        }
    }
    return(data.frame(day=unique(data$day),OR,lower,upper))
  }
  
  #function to get the odds per simulation
  getodds_all <- function(ddir){
    
    #read data
    daydata <- read.csv(file.path(ddir,"daydata.csv"))[,-c(1,2)]
    load(file.path(ddir,"settings.Rdata"))
  
    odds <- ldply(unique(daydata$days), function(day) getodds(subset(daydata, days==day)))
    odds$rhoE <- rep(settings$rho.E, nrow(odds))
    odds$epsA <- rep(settings$eps.A, nrow(odds))
    odds$epsD <- rep(settings$eps.D, nrow(odds))
  
    return(odds)
  }
  
  #combine the odds rations from all simulations
  odds_all<-ldply(datadir, function(ddir) getodds_all(ddir))
  odds_all$rhoE<-as.factor(odds_all$rhoE) # label = c(paste(expression(rho[R]*' = .3')),paste(expression(rho[R]*' = .6')),paste(expression(rho[R]*' = .9'))))
  odds_all$epsA<-as.factor(odds_all$epsA)
  odds_all$epsD<-as.factor(odds_all$epsD)
  
  #truncate the values to show max 100, for visibility reasons
  for (type in c('OR','lower','upper')){odds_all[[type]] <- sapply(odds_all[[type]], function(i) min(i,100))}

#write.csv(odds_all, 'data_figure9b_odds_withanti.csv', col.names = F)
  
#plot odds ratio's
ggplot(odds_all, aes(y= OR, x = day, shape = epsD)) +
  geom_point() +
  geom_errorbar(aes(ymin=lower, ymax=upper), width=.2) +
  facet_grid(epsA ~ rhoE, labeller = label_bquote(rows = rho['R'] == .(.9), cols = epsilon['A'] == .(30))) +
  #facet_grid(epsA ~ rhoE, labeller = label_bquote(rows = rho['R'] == .(rhoE, 1, 3), cols = epsilon['A'] == .(epsA, 3, 1))) +
  geom_hline(yintercept = 1, linetype=2) +
  #coord_flip() +
  coord_trans(y="log10") +
  #coord_cartesian(ylim=c(.01, 100)) + #limit the visible range
  scale_y_continuous(breaks=c(1, 10, 100),minor_breaks=c(seq(1,10,1),seq(20,100,10))) + # Ticks 
  scale_x_continuous(breaks=odds_all$day) +
  scale_shape_discrete(name=expression(epsilon['D'])) +
  #labs(title = expression('Relative disease risk - split by value of '*epsilon['A']*' (horizontal) and '*rho['R']*' (vertical)'), x = "Day", y = "Relative disease risk") +
  labs(x = "Day", y = "Relative disease risk") +
  theme_minimal() + theme(legend.position="bottom")

#ggsave('odds_no_ant.png', width = 12.5, height = 10, units = "cm")
#ggsave('odds_no_ant.pdf', width = 12.5, height = 10, units = "cm")
    
  
    # #assess assumptions
    # dwt(odds_model) #Independence of errors (Durbin-Watson)
    # densityplot(rstandard(odds_model)) #check for outliers
    # hist(dfbeta(odds_model)) #influential cases
    # densityplot(hatvalues(odds_model)) #influential cases
    # plot(odds_model)
    #
    # #look at model
    # summary(odds_model)
    #
    # #model fit by Chi2
    # Chi_sq <- odds_model$null.deviance-odds_model$deviance
    # chidf <- odds_model$df.null - odds_model$df.residual
    # chisq.prob <- 1 - pchisq(Chi_sq, chidf)
    # Chi_sq; chidf; chisq.prob
    #
    # #model fit by R2
    # R2.hl<-Chi_sq/odds_model$null.deviance
    # R.cs<-1-exp((odds_model$deviance-odds_model$null.deviance)/nrow(odds.data))
    # R.n<-R.cs/(1-(exp(-(odds_model$null.deviance/nrow(odds.data)))))
    # R2.hl; R.cs; R.n
  
}
```


#### between simulations - relative predictions about people becoming sick
```{r, echo = FALSE, message = FALSE, warning = FALSE}

# CREATE GRAPHS COMPARING DISEASE RISK IN THE VARIOUS SIMULATIONS (INVESTIGATING THE EFFECT OF THE PARAMETERS SET IN 'PARAMSETS')

if(length(datadir)>1){#only if it concerns multiple simulations

  #function to calculate the odds
  getodds2 <- function(data){
    if(sum(sapply(unique(data$sim.nr), function(nr)
      length(unique(data$sick[which(data$sim.nr==nr)]))<2))>0
      | length(unique(data$sim.nr))<2) #if all instances are either TRUE of FALSE
    {OR<-upper<-lower<-1
    } else {
      model <- with(data, glm(sick~sim.nr, family = binomial()))    #Store odds ratios
      if(model$converged==T){
        OR <- exp(model$coefficients)[2] #position [1] is the intercept...
        lower <- exp(confint(model))[2,1]
        upper <- exp(confint(model))[2,2]} else {
          OR<-upper<-lower<-1
        }
    }
    return(data.frame(OR,lower,upper))
  }
  
  #function to make the oddsplot
  makeoddsplot2 <- function(daydataall,sim1){  
    odds <- ldply(unique(daydataall$sim.nr), function(sim2) getodds2(daydataall[which(daydataall$sim.nr %in% c(sim1,sim2)),]))
    row.names(odds)<-paste0("vs.sim.",seq_along(row.names(odds)))
    odds$versus<-factor(seq_along(row.names(odds))) 
    # odds$versus<-factor(c(7:18,1:6), labels = c("30h - config. 1                        ", "30h - config. 2                        ", "30h - config. 3                        ", "30h - config. 4                        ", "30h - config. 5                        ", "30h - config. 6                        ","40h - config. 1                        ", "40h - config. 2                        ", "40h - config. 3                        ", "40h - config. 4                        ", "40h - config. 5                        ", "40h - config. 6                        ","50h - config. 1                        ", "50h - config. 2                        ", "50h - config. 3                        ", "50h - config. 4                        ", "50h - config. 5                        ", "50h - config. 6                        ")) #TEMP CHANGE
    
    print(kable(odds))

    write.csv(odds, 'suppl_odds_workvariations_9.csv', row.names = F)
    
    # #create plot of odds ratio's
    # p <- ggplot(odds, aes(y= OR, x = versus)) +
    #   geom_point() +
    #   geom_errorbar(aes(ymin=lower, ymax=upper), width=.2) +
    #   geom_hline(yintercept = 1, linetype=2) +
    #   #coord_flip() + 
    #   coord_trans(y="log2") +
    #   scale_x_continuous(breaks=odds$versus) +
    #   labs(x = paste(sim1,"versus sim..."), y = "stress, standardized") +
    #   theme_bw() + theme(axis.title.x = element_blank())
    # 
    # return(p)
    
    #create plot of odds ratio's and print immediately
    ggplot(odds, aes(y= OR, x = versus)) +
      geom_point() +
      geom_errorbar(aes(ymin=lower, ymax=upper), width=.2) +
      geom_hline(yintercept = 1, linetype=2) +
      #coord_flip() + 
      coord_trans(y="log2") +
      #scale_x_continuous(breaks=odds$versus) +
      scale_y_continuous(breaks=c(seq(.1,1,.1),seq(1,5,1))) +
      labs(x = paste(sim1,"versus sim..."), y = "relative risk of disease") +
      theme_bw() + theme(axis.title.x = element_blank()) + theme(axis.text.x = element_text(angle = 60))
    }
  
  #read data which contains information on whether or not are sick at the end of the simulation
  daydataall <- as.data.frame(matrix(unlist(sapply(datadir, function(i) read.csv(file.path(i,"daydata.csv"))[,c(4,7)])),ncol = 2*length(datadir)))
  daydataall<-daydataall[which(daydataall$V1==max(daydataall$V1)),seq(2,ncol(daydataall),2)] #only retain the last day
  
  #shape to long format
  names(daydataall)<-paste("sim",seq_along(datadir))
  daydataall<-gather(daydataall, key = sim.nr, value = sick)
  
  # #execute functions to create the odds plots
  # graphs <- lapply(unique(daydataall$sim.nr), function(sim1) makeoddsplot2(daydataall,sim1))
  # 
  # #multiplot(plotlist = graphs,cols = 3)
  # e=6 #start a new multiplot frame after each 4 plots
  # l_ply(seq(1,length(graphs),e), function(i) 
  # multiplot(plotlist = graphs[i:ifelse(i+e-1<length(graphs),i+e-1,length(graphs))], cols = 3))
  
  #run only to compare with the first plot
  makeoddsplot2(daydataall,"sim 1")
  #ggsave("worktimevar.pdf", width = 16, height = 12, units = "cm")
  #ggsave("worktimevar.png", width = 16, height = 12, units = "cm")


} else{print('NA')}
```

##Appendix

```{r, echo = FALSE, message = FALSE, warning = FALSE}

# IF ELASTICITY CONSTANT, ALLOSTATIC LOAD THRESHOLD AND DISEASE THRESHOLD WERE VARIED BETWEEN SIMULATIONS - CREATE (1.) GRID GRAPH OF ALLOSTATIC LOAD VS. STRESSOR FREQUENCY FOR THE DIFFERENT VALUES OF THE ELASTICITY CONSTANT AND ALLOSTATIC LOAD THRESHOLD, (2.) GRID GRAPH OF ALLOSTATIC LOAD VS. TIME OF THE FIRST 100 PEOPLE BECOMING SICK IN EACH SIMULATION

# 1. GRID GRAPH OF ALLOSTATIC LOAD VS. STRESSOR FREQUENCY FOR THE DIFFERENT VALUES OF THE ELASTICITY CONSTANT AND ALLOSTATIC LOAD THRESHOLD

if(length(datadir)>1 & sum(c('rho.E','eps.A','eps.D') %in% names(paramsets[[1]]))==3){

  #combine allostatic load from all simulations into one dataframe for plotting
  
  #this function retrieves the data from one simulation
  get_aload <- function(ddir){
  
    #read data
    daydata <- read.csv(file.path(ddir,"daydata.csv"))[,-c(1,2)]
    load(file.path(ddir,"settings.Rdata"))
  
    daydata$simperson<-as.factor(daydata$simperson)
    daydata$rho.E<-as.factor(rep(settings$rho.E,nrow(daydata)))
    daydata$eps.A<-as.factor(rep(settings$eps.A,nrow(daydata)))
    daydata$eps.D<-as.factor(rep(settings$eps.D,nrow(daydata)))

    return(daydata)}
  
  #here the data from the various simulations are combined
  aloadtrend <- ldply(datadir, function(ddir) get_aload(ddir))
  
  #write.csv(aloadtrend, "suppl_aloadtrend_noanti.csv", col.names = F)
  
  #plot the distributions of allostatic load - note that variation in disease threshold (eps.D) does not interest us at this point, therefore we only choose only one value of eps.D to plot. Also we standardize stressor frequencies
  ggplot(subset(aloadtrend, days == max(days) & eps.D == unique(eps.D)[1]), aes(x=scale(work.f.mean)[,1], y=Aload)) +
    geom_point() + geom_smooth(method="lm", se=F, colour="red") +
    facet_grid(rho.E ~ eps.A, scales="free") + 
    labs(x = "individual average work stressors (standardized)", y = "Allostatic load") +
    theme_minimal()

  # 2. GRID GRAPH OF ALLOSTATIC LOAD VS. TIME OF THE FIRST 100 PEOPLE BECOMING SICK IN EACH SIMULATION
  
  #get the data
  get_sick_profiles <- function(ddir){
  
    #read data of one simulation
    daydata <- read.csv(file.path(ddir,"daydata.csv"))[,-c(1,2)]
    load(file.path(ddir,"settings.Rdata"))
    
      #first determine which person number gets sick 
      getsick <- unique(daydata$simperson[which(daydata$Sick==T & daydata$days == max(daydata$days))])
      #maintain only the first 100 (or less if less than 100 get sick)
      getsick <- getsick[1:ifelse(length(getsick)>100,100,length(getsick))]

      #take the data of only the persons that got sick
      daydata <- subset(daydata,simperson %in% getsick)
      
      daydata$simperson<-as.factor(daydata$simperson)
      daydata$rho.E<-as.factor(rep(settings$rho.E,nrow(daydata)))
      daydata$eps.A<-as.factor(rep(settings$eps.A,nrow(daydata)))
      daydata$eps.D<-as.factor(rep(settings$eps.D,nrow(daydata)))
      
    return(daydata)}
  
  #combine the data of the different simulations
  aloadtrend_sick100 <- ldply(datadir, function(ddir) get_sick_profiles(ddir))
  
  #write.csv(aloadtrend_sick100, "suppl_aloadtrend_sick100_noanti.csv", col.names = F)

  ggplot(aloadtrend_sick100, aes(x=days, y=Aload, color = simperson)) +
    geom_line() + facet_grid(rho.E ~ eps.A) + 
    labs(title = 'allostatic load growth curves of 100 people becoming diseases', x = 'time [days]', y = "Allostatic load") + theme_bw() + theme(legend.position="none")  
}
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}

# FOR EACH SIMULATION CREATE (1.) GRAPHS OF ALLOSTATIC LOAD VS. STRESSOR FREQUENCY FOR THE DIFFERENT VALUES OF THE ELASTICITY CONSTANT AND ALLOSTATIC LOAD THRESHOLD, (2.) GRAPHS OF ALLOSTATIC LOAD VS. TIME OF THE FIRST 100 PEOPLE BECOMING SICK IN EACH SIMULATION -  ONLY IF THE SIMULATIONS DIDN'T CONCERN A COMPARISON OF ELASTICITY CONSTANT, ALLOSTATIC LOAD THRESHOLD AND DISEASE THRESHOLD WERE VARIED BETWEEN SIMULATIONS - 

if(length(datadir)>1 & sum(c('rho.E','eps.A','eps.D') %in% names(paramsets[[1]]))<3){

  
  aloadplot <- function(ddir){
    
    #read data
    daydata <- read.csv(file.path(ddir,"daydata.csv"))[,-c(1,2)]
    load(file.path(ddir,"settings.Rdata"))
    daydata$simperson<-as.factor(daydata$simperson) # convert type to factor for plotting purposes
    
    # (2.) GRAPHS OF ALLOSTATIC LOAD VS. TIME OF THE FIRST 100 PEOPLE BECOMING SICK IN EACH SIMULATION

    #determine which person number gets sick and which stays healthy
    getsick <- unique(daydata$simperson[which(daydata$Sick==T & daydata$days == max(daydata$days))])
    healthy <- unique(daydata$simperson[which(daydata$Sick==F & daydata$days == max(daydata$days))])
    #keep only the first 100 at max
    getsick <- getsick[1:ifelse(length(getsick)>100,100,length(getsick))]
    healthy <- healthy[1:ifelse(length(healthy)>100,100,length(healthy))]
    
    #get data for the people that got sick
    ggplot(subset(daydata,simperson %in% getsick), aes(x=days, y=Aload, color = simperson)) +
      geom_line() + ylab("Allostatic load") + xlab("time [days]") + 
      ggtitle(paste("Allostatic load development of people that get sick", unlist(strsplit(ddir, "/"))[length(unlist(strsplit(ddir, "/")))])) + 
      theme_bw() + theme(legend.position="none")
    
    #get data for the people that got stayed healthy
    ggplot(subset(daydata,simperson %in% healthy), aes(x=days, y=Aload, color = simperson)) +
      geom_line() + ylab("Allostatic load") + xlab("time [days]") + 
      ggtitle(paste("Allostatic load development of people that get sick", unlist(strsplit(ddir, "/"))[length(unlist(strsplit(ddir, "/")))])) + 
      theme_bw() + theme(legend.position="none")
  
    # (1.) GRAPHS OF ALLOSTATIC LOAD VS. STRESSOR FREQUENCY FOR THE DIFFERENT VALUES OF THE ELASTICITY CONSTANT AND ALLOSTATIC LOAD THRESHOLD
    
    #create a plot of all allostatic load vs. stressor level
    daydata$days <- as.factor(daydata$days); levels(daydata$days) <- paste0("day",daydata$days)  
    
    ggplot(daydata, aes(x=work.f.mean, y=Aload)) +
      geom_point() + facet_wrap( ~ days, ncol=length(unique(daydata$days))) + geom_smooth(method="auto", se=F, colour="grey") + ggtitle(paste("Allostatic load vs. work stress ", unlist(strsplit(ddir, "/"))[length(unlist(strsplit(ddir, "/")))])) +
      ylab("Allostatic load") + xlab("average frequency of stressors") + theme_bw() + 
      theme(
        strip.background = element_blank(),
        strip.text.x = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank()
      )
  }
  
  #get graohs per simulation
  lapply(datadir, function(i) aloadplot(i))
  }
```


##### Time taken   
```{r, echo = FALSE, message = FALSE, warning = FALSE}
print('Simulation time [min]:')
      if(exists("totalsimtime")){print(totalsimtime)}
print('Rendering time [min]:')
  print(round(as.numeric(difftime(Sys.time(), start.time, unit="mins"))))
print('Total time [min]:')
print(ifelse(exists("totalsimtime"),totalsimtime,0) + round(as.numeric(difftime(Sys.time(), start.time, unit="mins"))))

```


